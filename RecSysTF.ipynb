{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0fa81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from itertools import permutations,combinations\n",
    "from collections import Counter\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Optional, Text, Tuple, Union\n",
    "import abc\n",
    "import contextlib\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0406c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             object\n",
       "timestamp             int64\n",
       "user_id              object\n",
       "customer_city        object\n",
       "product_category     object\n",
       "product_id           object\n",
       "quantity             object\n",
       "price               float64\n",
       "review_score          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36b8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardize item data types, especially string, float, and integer\n",
    "\n",
    "masterdf['user_id'] = masterdf['user_id'].astype(str)\n",
    "masterdf['product_id'] = masterdf['product_id'].astype(str)\n",
    "masterdf['quantity'] = masterdf['quantity'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d57eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             object\n",
       "timestamp             int64\n",
       "user_id              object\n",
       "customer_city        object\n",
       "product_category     object\n",
       "product_id           object\n",
       "quantity            float64\n",
       "price               float64\n",
       "review_score          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e092ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_dict = masterdf.groupby(['user_id', 'product_id', 'timestamp'])[ 'quantity'].sum().reset_index()\n",
    "\n",
    "interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n",
    "interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n",
    "\n",
    "items_dict = masterdf[['product_id']].drop_duplicates()\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)\n",
    "\n",
    "interactions = interactions.map(lambda x: {\n",
    "                                            'user_id' : x['user_id'], \n",
    "                                            'product_id' : x['product_id'], \n",
    "                                            'quantity' : float(x['quantity']),\n",
    "                                            \"timestamp\": x[\"timestamp\"] })\n",
    "\n",
    "items = items.map(lambda x: x['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707aed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get unique item and user id's as a lookup table\n",
    "unique_item_titles = np.unique(np.concatenate(list(items.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(interactions.batch(1000).map(lambda x: x[\"user_id\"]))))\n",
    "\n",
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(len(masterdf), seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(round(len(masterdf)*0.6))\n",
    "test = shuffled.skip(round(len(masterdf)*0.6)).take(round(len(masterdf)*0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0d89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Candidate model (item)\n",
    "        ### This is Keras preprocessing layers to first convert user ids to integers, \n",
    "        ### and then convert those to user embeddings via an Embedding layer. \n",
    "        ### We use the list of unique user ids we computed earlier as a vocabulary:\n",
    "        item_model = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                        vocabulary=unique_item_titles, mask_token=None),\n",
    "                                        tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "                                        ])\n",
    "        ### we pass the embedding layer into item model\n",
    "        self.item_model: tf.keras.Model = item_model\n",
    "            \n",
    "        ### Query model (users)    \n",
    "        user_model = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                        vocabulary=unique_user_ids, mask_token=None),\n",
    "                                        # We add an additional embedding to account for unknown tokens.\n",
    "                                        tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "                                        ])\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        \n",
    "        ### for retrieval model. we take top-k accuracy as metrics\n",
    "        metrics = tfrs.metrics.FactorizedTopK(\n",
    "                                            candidates=items.batch(128).map(item_model))\n",
    "                    \n",
    "        # define the task, which is retrieval                                      \n",
    "        task = tfrs.tasks.Retrieval(\n",
    "                                    metrics=metrics\n",
    "                                    )\n",
    "       \n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_movie_embeddings = self.item_model(features[\"product_id\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73e7d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 42s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0136 - factorized_top_k/top_10_categorical_accuracy: 0.0225 - factorized_top_k/top_50_categorical_accuracy: 0.0653 - factorized_top_k/top_100_categorical_accuracy: 0.1009 - loss: 186584.7639 - regularization_loss: 0.0000e+00 - total_loss: 186584.7639\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 41s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0961 - factorized_top_k/top_5_categorical_accuracy: 0.2616 - factorized_top_k/top_10_categorical_accuracy: 0.3230 - factorized_top_k/top_50_categorical_accuracy: 0.4957 - factorized_top_k/top_100_categorical_accuracy: 0.5903 - loss: 183019.7986 - regularization_loss: 0.0000e+00 - total_loss: 183019.7986\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 43s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.2213 - factorized_top_k/top_5_categorical_accuracy: 0.5101 - factorized_top_k/top_10_categorical_accuracy: 0.5801 - factorized_top_k/top_50_categorical_accuracy: 0.7369 - factorized_top_k/top_100_categorical_accuracy: 0.8031 - loss: 168717.1840 - regularization_loss: 0.0000e+00 - total_loss: 168717.1840\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 45s 6s/step - factorized_top_k/top_1_categorical_accuracy: 0.2628 - factorized_top_k/top_5_categorical_accuracy: 0.6114 - factorized_top_k/top_10_categorical_accuracy: 0.6793 - factorized_top_k/top_50_categorical_accuracy: 0.8149 - factorized_top_k/top_100_categorical_accuracy: 0.8695 - loss: 147119.4583 - regularization_loss: 0.0000e+00 - total_loss: 147119.4583\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 43s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.2725 - factorized_top_k/top_5_categorical_accuracy: 0.6714 - factorized_top_k/top_10_categorical_accuracy: 0.7366 - factorized_top_k/top_50_categorical_accuracy: 0.8564 - factorized_top_k/top_100_categorical_accuracy: 0.9010 - loss: 127987.9479 - regularization_loss: 0.0000e+00 - total_loss: 127987.9479\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 43s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.2759 - factorized_top_k/top_5_categorical_accuracy: 0.7097 - factorized_top_k/top_10_categorical_accuracy: 0.7731 - factorized_top_k/top_50_categorical_accuracy: 0.8817 - factorized_top_k/top_100_categorical_accuracy: 0.9204 - loss: 114838.4470 - regularization_loss: 0.0000e+00 - total_loss: 114838.4470\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 43s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.2840 - factorized_top_k/top_5_categorical_accuracy: 0.7331 - factorized_top_k/top_10_categorical_accuracy: 0.7966 - factorized_top_k/top_50_categorical_accuracy: 0.8981 - factorized_top_k/top_100_categorical_accuracy: 0.9334 - loss: 106371.9045 - regularization_loss: 0.0000e+00 - total_loss: 106371.9045\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 44s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.2850 - factorized_top_k/top_5_categorical_accuracy: 0.7493 - factorized_top_k/top_10_categorical_accuracy: 0.8119 - factorized_top_k/top_50_categorical_accuracy: 0.9095 - factorized_top_k/top_100_categorical_accuracy: 0.9413 - loss: 100779.1823 - regularization_loss: 0.0000e+00 - total_loss: 100779.1823\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 44s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.2875 - factorized_top_k/top_5_categorical_accuracy: 0.7616 - factorized_top_k/top_10_categorical_accuracy: 0.8243 - factorized_top_k/top_50_categorical_accuracy: 0.9178 - factorized_top_k/top_100_categorical_accuracy: 0.9469 - loss: 96924.6745 - regularization_loss: 0.0000e+00 - total_loss: 96924.6745\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 62s 8s/step - factorized_top_k/top_1_categorical_accuracy: 0.2896 - factorized_top_k/top_5_categorical_accuracy: 0.7710 - factorized_top_k/top_10_categorical_accuracy: 0.8333 - factorized_top_k/top_50_categorical_accuracy: 0.9237 - factorized_top_k/top_100_categorical_accuracy: 0.9513 - loss: 94138.7222 - regularization_loss: 0.0000e+00 - total_loss: 94138.7222\n",
      "13/13 [==============================] - 17s 884ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0066 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0376 - factorized_top_k/top_50_categorical_accuracy: 0.0952 - factorized_top_k/top_100_categorical_accuracy: 0.1461 - loss: 39895.4358 - regularization_loss: 0.0000e+00 - total_loss: 39895.4358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.006603329908102751,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.025284545496106148,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.03764462471008301,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.09523092955350876,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.1461198329925537,\n",
       " 'loss': 38759.34375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 38759.34375}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fitting and evaluating\n",
    "\n",
    "### we choose the dimensionality of the query and candicate representation.\n",
    "embedding_dimension = 32\n",
    "\n",
    "## we pass the model, which is the same model we created in the query and candidate tower, into the model\n",
    "item_model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                vocabulary=unique_item_titles, mask_token=None),\n",
    "                                tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "                                ])\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                vocabulary=unique_user_ids, mask_token=None),\n",
    "                                # We add an additional embedding to account for unknown tokens.\n",
    "                                tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "                                ])\n",
    "\n",
    "model = RetailModel(user_model, item_model)\n",
    "\n",
    "# a smaller learning rate may make the model move slower and prone to overfitting, so we stick to 0.1\n",
    "# other optimizers, such as SGD and Adam, are listed here https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "cached_train = train.shuffle(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "## fit the model with ten epochs\n",
    "model_hist = model.fit(cached_train, epochs=10)\n",
    "\n",
    "#evaluate the model\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541306fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 12s 889ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0066 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0376 - factorized_top_k/top_50_categorical_accuracy: 0.0952 - factorized_top_k/top_100_categorical_accuracy: 0.1461 - loss: 39895.4358 - regularization_loss: 0.0000e+00 - total_loss: 39895.4358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.006603329908102751,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.025284545496106148,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.03764462471008301,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.09523092955350876,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.1461198329925537,\n",
       " 'loss': 38759.34375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 38759.34375}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e83e0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20af6d92d00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochs = [i for i in range(10)]\n",
    "\n",
    "plt.plot(epochs, model_hist.history[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"accuracy\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea1c8c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<MapDataset shapes: (None, 32), types: tf.float32>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e6e011af1cab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorized_top_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBruteForce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# recommends movies out of the entire movies dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get recommendations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py\u001b[0m in \u001b[0;36mindex\u001b[1;34m(self, candidates, identifiers)\u001b[0m\n\u001b[0;32m    517\u001b[0m       \u001b[0midentifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       raise ValueError(\n\u001b[0;32m    521\u001b[0m           f\"The candidates tensor must be 2D (got {candidates.shape}).\")\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mrank\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    837\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m   \"\"\"\n\u001b[1;32m--> 839\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mrank_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mrank_internal\u001b[1;34m(input, name, optimize)\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m       \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    344\u001b[0m                                          as_ref=False):\n\u001b[0;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<MapDataset shapes: (None, 32), types: tf.float32>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index(items.batch(100).map(model.item_model), items)\n",
    "\n",
    "# Get recommendations.\n",
    "j = str(40)\n",
    "_, titles = index(tf.constant([j]))\n",
    "print(f\"Recommendations for user %s: {titles[0]}\" %(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442b091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for movies.\n",
    "        self.movie_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_item_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          # Learn multiple dense layers.\n",
    "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "          # Make rating predictions in the final layer.\n",
    "          tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, movie_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        movie_embedding = self.movie_embeddings(movie_title)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56c06d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "          loss = tf.keras.losses.MeanSquaredError(),\n",
    "          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        rating_predictions = self.ranking_model(\n",
    "            (features[\"user_id\"], features[\"product_id\"]))\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=features[\"quantity\"], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c59482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 106ms/step - root_mean_squared_error: 1.0262 - loss: 0.8871 - regularization_loss: 0.0000e+00 - total_loss: 0.8871\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 44ms/step - root_mean_squared_error: 0.1390 - loss: 0.0161 - regularization_loss: 0.0000e+00 - total_loss: 0.0161\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 46ms/step - root_mean_squared_error: 0.0136 - loss: 1.9098e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.9098e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0176 - loss: 3.1811e-04 - regularization_loss: 0.0000e+00 - total_loss: 3.1811e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0218 - loss: 4.8438e-04 - regularization_loss: 0.0000e+00 - total_loss: 4.8438e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0250 - loss: 6.2669e-04 - regularization_loss: 0.0000e+00 - total_loss: 6.2669e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0259 - loss: 6.5683e-04 - regularization_loss: 0.0000e+00 - total_loss: 6.5683e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0240 - loss: 5.5687e-04 - regularization_loss: 0.0000e+00 - total_loss: 5.5687e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0204 - loss: 3.9800e-04 - regularization_loss: 0.0000e+00 - total_loss: 3.9800e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0163 - loss: 2.5454e-04 - regularization_loss: 0.0000e+00 - total_loss: 2.5454e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 51ms/step - root_mean_squared_error: 0.0127 - loss: 1.5441e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5441e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 52ms/step - root_mean_squared_error: 0.0099 - loss: 9.3624e-05 - regularization_loss: 0.0000e+00 - total_loss: 9.3624e-05\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 52ms/step - root_mean_squared_error: 0.0079 - loss: 5.9572e-05 - regularization_loss: 0.0000e+00 - total_loss: 5.9572e-05\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0066 - loss: 4.1423e-05 - regularization_loss: 0.0000e+00 - total_loss: 4.1423e-05\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 52ms/step - root_mean_squared_error: 0.0058 - loss: 3.2089e-05 - regularization_loss: 0.0000e+00 - total_loss: 3.2089e-05\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0054 - loss: 2.7432e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.7432e-05\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0051 - loss: 2.5175e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.5175e-05\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0050 - loss: 2.4111e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.4111e-05\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0050 - loss: 2.3618e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.3618e-05\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0049 - loss: 2.3383e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.3383e-05\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0049 - loss: 2.3255e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.3255e-05\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0049 - loss: 2.3163e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.3163e-05\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0049 - loss: 2.3077e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.3077e-05\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0049 - loss: 2.2985e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2985e-05\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0049 - loss: 2.2885e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2885e-05\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0049 - loss: 2.2777e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2777e-05\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0049 - loss: 2.2663e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2663e-05\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0049 - loss: 2.2545e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2545e-05\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0048 - loss: 2.2424e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2424e-05\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0048 - loss: 2.2301e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2301e-05\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 54ms/step - root_mean_squared_error: 0.0048 - loss: 2.2177e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2177e-05\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 55ms/step - root_mean_squared_error: 0.0048 - loss: 2.2054e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.2054e-05\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 55ms/step - root_mean_squared_error: 0.0048 - loss: 2.1931e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1931e-05\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 54ms/step - root_mean_squared_error: 0.0048 - loss: 2.1809e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1809e-05\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 51ms/step - root_mean_squared_error: 0.0048 - loss: 2.1688e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1688e-05\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0048 - loss: 2.1568e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1568e-05\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0047 - loss: 2.1449e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1449e-05\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0047 - loss: 2.1331e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1331e-05\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0047 - loss: 2.1215e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1215e-05\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0047 - loss: 2.1100e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.1100e-05\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 52ms/step - root_mean_squared_error: 0.0047 - loss: 2.0986e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0986e-05\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 53ms/step - root_mean_squared_error: 0.0047 - loss: 2.0873e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0873e-05\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 55ms/step - root_mean_squared_error: 0.0047 - loss: 2.0762e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0762e-05\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 1s 67ms/step - root_mean_squared_error: 0.0047 - loss: 2.0652e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0652e-05\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 57ms/step - root_mean_squared_error: 0.0046 - loss: 2.0543e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0543e-05\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 57ms/step - root_mean_squared_error: 0.0046 - loss: 2.0435e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0435e-05\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 54ms/step - root_mean_squared_error: 0.0046 - loss: 2.0329e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0329e-05\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0046 - loss: 2.0223e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0223e-05\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 46ms/step - root_mean_squared_error: 0.0046 - loss: 2.0119e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0119e-05\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0046 - loss: 2.0016e-05 - regularization_loss: 0.0000e+00 - total_loss: 2.0016e-05\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0046 - loss: 1.9914e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9914e-05\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0046 - loss: 1.9813e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9813e-05\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0046 - loss: 1.9714e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9714e-05\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 52ms/step - root_mean_squared_error: 0.0045 - loss: 1.9615e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9615e-05\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 51ms/step - root_mean_squared_error: 0.0045 - loss: 1.9517e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9517e-05\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0045 - loss: 1.9421e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9421e-05\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 51ms/step - root_mean_squared_error: 0.0045 - loss: 1.9325e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9325e-05\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0045 - loss: 1.9231e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9231e-05\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0045 - loss: 1.9137e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9137e-05\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0045 - loss: 1.9045e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.9045e-05\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0045 - loss: 1.8953e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8953e-05\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0045 - loss: 1.8863e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8863e-05\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0044 - loss: 1.8773e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8773e-05\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0044 - loss: 1.8684e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8684e-05\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0044 - loss: 1.8596e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8596e-05\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0044 - loss: 1.8509e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8509e-05\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0044 - loss: 1.8422e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8422e-05\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 52ms/step - root_mean_squared_error: 0.0044 - loss: 1.8337e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8337e-05\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 54ms/step - root_mean_squared_error: 0.0044 - loss: 1.8252e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8252e-05\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 56ms/step - root_mean_squared_error: 0.0044 - loss: 1.8169e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8169e-05\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 51ms/step - root_mean_squared_error: 0.0044 - loss: 1.8086e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8086e-05\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 51ms/step - root_mean_squared_error: 0.0044 - loss: 1.8004e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.8004e-05\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0044 - loss: 1.7922e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7922e-05\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0043 - loss: 1.7842e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7842e-05\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0043 - loss: 1.7762e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7762e-05\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0043 - loss: 1.7683e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7683e-05\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0043 - loss: 1.7605e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7605e-05\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0043 - loss: 1.7527e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7527e-05\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0043 - loss: 1.7451e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7451e-05\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0043 - loss: 1.7375e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7375e-05\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0043 - loss: 1.7299e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7299e-05\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0043 - loss: 1.7225e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7225e-05\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0043 - loss: 1.7151e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7151e-05\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.0043 - loss: 1.7078e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7078e-05\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0042 - loss: 1.7005e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.7005e-05\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0042 - loss: 1.6934e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6934e-05\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0042 - loss: 1.6862e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6862e-05\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 48ms/step - root_mean_squared_error: 0.0042 - loss: 1.6792e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6792e-05\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0042 - loss: 1.6722e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6722e-05\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0042 - loss: 1.6653e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6653e-05\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0042 - loss: 1.6584e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6584e-05\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0042 - loss: 1.6516e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6516e-05\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0042 - loss: 1.6449e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6449e-05\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0042 - loss: 1.6382e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6382e-05\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0042 - loss: 1.6316e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6316e-05\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 46ms/step - root_mean_squared_error: 0.0042 - loss: 1.6251e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6251e-05\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.0041 - loss: 1.6186e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6186e-05\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0041 - loss: 1.6121e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6121e-05\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 47ms/step - root_mean_squared_error: 0.0041 - loss: 1.6057e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.6057e-05\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 46ms/step - root_mean_squared_error: 0.0041 - loss: 1.5994e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.5994e-05\n",
      "13/13 [==============================] - 3s 29ms/step - root_mean_squared_error: 0.0033 - loss: 1.0942e-05 - regularization_loss: 0.0000e+00 - total_loss: 1.0942e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 0.0033059418201446533,\n",
       " 'loss': 1.1109805200248957e-05,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.1109805200248957e-05}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RetailModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.5))\n",
    "\n",
    "cached_train = train.shuffle(len(masterdf)).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=100)\n",
    "\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "800d2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic housekeeping to prepare feature vocabularies\n",
    "\n",
    "## timestamp is an exmaple of continuous features, which needs to be rescaled, or otherwise it will be \n",
    "## too large for the model.\n",
    "## there are other methods to reduce the size of the timestamp, ,such as standardization and normalization\n",
    "## here we use discretization, which puts them into buckets of categorical features, \n",
    "\n",
    "timestamps = np.concatenate(list(interactions.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,)\n",
    "\n",
    "item_titles = interactions.batch(round(len(masterdf)*0.1)).map(lambda x: x[\"product_id\"])\n",
    "user_ids = interactions.batch(round(len(masterdf)*0.1)).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_item_titles = np.unique(np.concatenate(list(item_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a6a0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(len(masterdf), seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(round(len(masterdf)*0.6))\n",
    "test = shuffled.skip(round(len(masterdf)*0.6)).take(round(len(masterdf)*0.6))\n",
    "\n",
    "cached_train = train.shuffle(len(masterdf)).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff85c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### user model\n",
    "\n",
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, use_timestamps):\n",
    "        super().__init__()\n",
    "\n",
    "        self._use_timestamps = use_timestamps\n",
    "\n",
    "        ## embed user id from unique_user_ids\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "        ])\n",
    "\n",
    "        ## embed timestamp\n",
    "        if use_timestamps:\n",
    "            self.timestamp_embedding = tf.keras.Sequential([\n",
    "              tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),\n",
    "              tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "            ])\n",
    "            self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "\n",
    "            self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if not self._use_timestamps:\n",
    "              return self.user_embedding(inputs[\"user_id\"])\n",
    "\n",
    "        ## all features here\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "            self.normalized_timestamp(inputs[\"timestamp\"]),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7911fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### candidate model\n",
    "\n",
    "class ItemModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        ## embed title from unique_item_titles\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=unique_item_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_item_titles) + 1, 32)\n",
    "        ])\n",
    "\n",
    "        ## processing text features: item title vectorizer (see self.title_vectorizer)\n",
    "        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        ## we apply title vectorizer to items\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "          self.title_vectorizer,\n",
    "          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer.adapt(items)\n",
    "\n",
    "    def call(self, titles):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(titles),\n",
    "            self.title_text_embedding(titles),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daddc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, use_timestamps):\n",
    "        super().__init__()\n",
    "        \n",
    "        ## query model is user model\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "          UserModel(use_timestamps),\n",
    "          tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        \n",
    "        ## candidate model is the item model\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "          ItemModel(),\n",
    "          tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        \n",
    "        ## retrieval task, choose metrics\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=items.batch(128).map(self.candidate_model),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        # We only pass the user id and timestamp features into the query model. This\n",
    "        # is to ensure that the training inputs would have the same keys as the\n",
    "        # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "        # error when loading the query model after saving it.\n",
    "        \n",
    "        query_embeddings = self.query_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"timestamp\": features[\"timestamp\"],\n",
    "        })\n",
    "        \n",
    "        item_embeddings = self.candidate_model(features[\"product_id\"])\n",
    "\n",
    "        return self.task(query_embeddings, item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6447cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "78/78 [==============================] - 25s 286ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0109 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0297 - factorized_top_k/top_50_categorical_accuracy: 0.0733 - factorized_top_k/top_100_categorical_accuracy: 0.1138 - loss: 15460.0235 - regularization_loss: 0.0000e+00 - total_loss: 15460.0235\n",
      "Epoch 2/3\n",
      "78/78 [==============================] - 27s 309ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0232 - factorized_top_k/top_5_categorical_accuracy: 0.0967 - factorized_top_k/top_10_categorical_accuracy: 0.1442 - factorized_top_k/top_50_categorical_accuracy: 0.3182 - factorized_top_k/top_100_categorical_accuracy: 0.4224 - loss: 13813.9302 - regularization_loss: 0.0000e+00 - total_loss: 13813.9302\n",
      "Epoch 3/3\n",
      "78/78 [==============================] - 25s 289ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1043 - factorized_top_k/top_5_categorical_accuracy: 0.3612 - factorized_top_k/top_10_categorical_accuracy: 0.4279 - factorized_top_k/top_50_categorical_accuracy: 0.6019 - factorized_top_k/top_100_categorical_accuracy: 0.6871 - loss: 10469.2868 - regularization_loss: 0.0000e+00 - total_loss: 10469.2868\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "26/26 [==============================] - 19s 593ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0062 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0360 - factorized_top_k/top_50_categorical_accuracy: 0.1007 - factorized_top_k/top_100_categorical_accuracy: 0.1554 - loss: 36406.0856 - regularization_loss: 0.0000e+00 - total_loss: 36406.0856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.006236536893993616,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.02241578884422779,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.036008238792419434,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.1006782129406929,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.15537725389003754,\n",
       " 'loss': 34742.41796875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 34742.41796875}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RetailModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=3)\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f24c171e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:121 adapt_step  *\n        self._adapt_maybe_build(data)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:284 _adapt_maybe_build  **\n        self.build(data_shape)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\normalization.py:145 build\n        raise ValueError(\n\n    ValueError: All `axis` values to be kept must have known shape. Got axis: (-1,), input shape: [None], with unknown axis at index: 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3051827288b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mRetailModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_timestamps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-37d59cb5a982>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, use_timestamps)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m## query model is user model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         self.query_model = tf.keras.Sequential([\n\u001b[1;32m----> 8\u001b[1;33m           \u001b[0mUserModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_timestamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m           \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         ])\n",
      "\u001b[1;32m<ipython-input-20-a67fde831279>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, use_timestamps)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized_timestamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[0;32m    246\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:121 adapt_step  *\n        self._adapt_maybe_build(data)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:284 _adapt_maybe_build  **\n        self.build(data_shape)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\normalization.py:145 build\n        raise ValueError(\n\n    ValueError: All `axis` values to be kept must have known shape. Got axis: (-1,), input shape: [None], with unknown axis at index: 0\n"
     ]
    }
   ],
   "source": [
    "model =  RetailModel(use_timestamps=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d9b9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 rating_weight: float, retrieval_weight: float) -> None:\n",
    "        # We take the loss weights in the constructor: this allows us to instantiate\n",
    "        # several model objects with different loss weights.\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # item models.\n",
    "        self.item_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_item_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "            \n",
    "        ## user model    \n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and item embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        \n",
    "        ## this is Relu-Based DNN\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # rating and retrieval task.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "            \n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=items.batch(128).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        \n",
    "        # And pick out the item features and pass them into the item model.\n",
    "        item_embeddings = self.item_model(features[\"product_id\"])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            item_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and item embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, item_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ## ratings go here as a method to compute loss\n",
    "        ratings = features.pop(\"quantity\")\n",
    "\n",
    "        user_embeddings, item_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, item_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7e09718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 28s 1s/step - root_mean_squared_error: 0.2692 - factorized_top_k/top_1_categorical_accuracy: 2.5084e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0013 - factorized_top_k/top_10_categorical_accuracy: 0.0027 - factorized_top_k/top_50_categorical_accuracy: 0.0144 - factorized_top_k/top_100_categorical_accuracy: 0.0294 - loss: 0.0672 - regularization_loss: 0.0000e+00 - total_loss: 0.0672\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 24s 1s/step - root_mean_squared_error: 0.0125 - factorized_top_k/top_1_categorical_accuracy: 2.3830e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0012 - factorized_top_k/top_10_categorical_accuracy: 0.0027 - factorized_top_k/top_50_categorical_accuracy: 0.0144 - factorized_top_k/top_100_categorical_accuracy: 0.0295 - loss: 1.5430e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5430e-04\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 28s 1s/step - root_mean_squared_error: 0.0120 - factorized_top_k/top_1_categorical_accuracy: 2.3203e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0012 - factorized_top_k/top_10_categorical_accuracy: 0.0027 - factorized_top_k/top_50_categorical_accuracy: 0.0144 - factorized_top_k/top_100_categorical_accuracy: 0.0295 - loss: 1.4435e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.4435e-04\n",
      "26/26 [==============================] - 13s 402ms/step - root_mean_squared_error: 0.0116 - factorized_top_k/top_1_categorical_accuracy: 1.6932e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0013 - factorized_top_k/top_10_categorical_accuracy: 0.0024 - factorized_top_k/top_50_categorical_accuracy: 0.0142 - factorized_top_k/top_100_categorical_accuracy: 0.0284 - loss: 1.3539e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.3539e-04\n",
      "Retrieval top-100 accuracy: 0.028.\n",
      "Ranking RMSE: 0.012.\n"
     ]
    }
   ],
   "source": [
    "model = Model(rating_weight=1.0, retrieval_weight=0.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f97dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 28s 1s/step - root_mean_squared_error: 0.9953 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0165 - factorized_top_k/top_10_categorical_accuracy: 0.0268 - factorized_top_k/top_50_categorical_accuracy: 0.0773 - factorized_top_k/top_100_categorical_accuracy: 0.1179 - loss: 69706.4712 - regularization_loss: 0.0000e+00 - total_loss: 69706.4712\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 26s 1s/step - root_mean_squared_error: 0.9840 - factorized_top_k/top_1_categorical_accuracy: 0.1023 - factorized_top_k/top_5_categorical_accuracy: 0.2763 - factorized_top_k/top_10_categorical_accuracy: 0.3424 - factorized_top_k/top_50_categorical_accuracy: 0.5164 - factorized_top_k/top_100_categorical_accuracy: 0.6073 - loss: 67502.4353 - regularization_loss: 0.0000e+00 - total_loss: 67502.4353\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 27s 1s/step - root_mean_squared_error: 0.9615 - factorized_top_k/top_1_categorical_accuracy: 0.2138 - factorized_top_k/top_5_categorical_accuracy: 0.5019 - factorized_top_k/top_10_categorical_accuracy: 0.5733 - factorized_top_k/top_50_categorical_accuracy: 0.7319 - factorized_top_k/top_100_categorical_accuracy: 0.7993 - loss: 59859.8571 - regularization_loss: 0.0000e+00 - total_loss: 59859.8571\n",
      "26/26 [==============================] - 14s 530ms/step - root_mean_squared_error: 0.9530 - factorized_top_k/top_1_categorical_accuracy: 0.0080 - factorized_top_k/top_5_categorical_accuracy: 0.0417 - factorized_top_k/top_10_categorical_accuracy: 0.0645 - factorized_top_k/top_50_categorical_accuracy: 0.1627 - factorized_top_k/top_100_categorical_accuracy: 0.2383 - loss: 33462.4123 - regularization_loss: 0.0000e+00 - total_loss: 33462.4123\n",
      "Retrieval top-100 accuracy: 0.238.\n",
      "Ranking RMSE: 0.953.\n"
     ]
    }
   ],
   "source": [
    "model = Model(rating_weight=0.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2171cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 26s 1s/step - root_mean_squared_error: 0.2868 - factorized_top_k/top_1_categorical_accuracy: 0.0025 - factorized_top_k/top_5_categorical_accuracy: 0.0134 - factorized_top_k/top_10_categorical_accuracy: 0.0219 - factorized_top_k/top_50_categorical_accuracy: 0.0620 - factorized_top_k/top_100_categorical_accuracy: 0.0955 - loss: 34873.6921 - regularization_loss: 0.0000e+00 - total_loss: 34873.6921\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 27s 1s/step - root_mean_squared_error: 0.0580 - factorized_top_k/top_1_categorical_accuracy: 0.0404 - factorized_top_k/top_5_categorical_accuracy: 0.1405 - factorized_top_k/top_10_categorical_accuracy: 0.1906 - factorized_top_k/top_50_categorical_accuracy: 0.3500 - factorized_top_k/top_100_categorical_accuracy: 0.4470 - loss: 34551.0197 - regularization_loss: 0.0000e+00 - total_loss: 34551.0197\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 27s 1s/step - root_mean_squared_error: 0.0726 - factorized_top_k/top_1_categorical_accuracy: 0.1452 - factorized_top_k/top_5_categorical_accuracy: 0.3618 - factorized_top_k/top_10_categorical_accuracy: 0.4349 - factorized_top_k/top_50_categorical_accuracy: 0.6086 - factorized_top_k/top_100_categorical_accuracy: 0.6903 - loss: 32856.6043 - regularization_loss: 0.0000e+00 - total_loss: 32856.6043\n",
      "26/26 [==============================] - 14s 527ms/step - root_mean_squared_error: 0.0772 - factorized_top_k/top_1_categorical_accuracy: 0.0077 - factorized_top_k/top_5_categorical_accuracy: 0.0441 - factorized_top_k/top_10_categorical_accuracy: 0.0690 - factorized_top_k/top_50_categorical_accuracy: 0.1713 - factorized_top_k/top_100_categorical_accuracy: 0.2466 - loss: 16713.2822 - regularization_loss: 0.0000e+00 - total_loss: 16713.2822\n",
      "Retrieval top-100 accuracy: 0.247.\n",
      "Ranking RMSE: 0.077.\n"
     ]
    }
   ],
   "source": [
    "model = Model(rating_weight=0.5, retrieval_weight=0.5)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f52fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define interactions data and user data\n",
    "\n",
    "### interactions \n",
    "### here we create a reference table of the user , item, and quantity purchased\n",
    "interactions_dict = masterdf.groupby(['user_id', \n",
    "                                      'customer_city',\n",
    "                                      'product_category',\n",
    "                                      'product_id', \n",
    "                                      'timestamp'])['quantity'].sum().reset_index()\n",
    "\n",
    "interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n",
    "interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n",
    "\n",
    "## item features\n",
    "items_dict = masterdf[['product_id']].drop_duplicates()\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)\n",
    "\n",
    "## map the features in interactions and items\n",
    "\n",
    "# Select the basic features.\n",
    "interactions = interactions.map(lambda x: {\n",
    "    'user_id' : str(x['user_id']), \n",
    "    'customer_city' : str(x['customer_city']),\n",
    "    'product_id' : str(x['product_id']), \n",
    "    'product_category' : str(x['product_category']),   \n",
    "    'quantity' : int(x['quantity']),\n",
    "    \"timestamp\": int(x[\"timestamp\"])\n",
    "})\n",
    "\n",
    "items = items.map(lambda x: str(x['product_id']))\n",
    "city = interactions.map(lambda x: str(x['customer_city']))\n",
    "category = interactions.map(lambda x: str(x['product_category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c98cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_item_titles = np.unique(np.concatenate(list(items.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(interactions.batch(1_000).map(lambda x: x[\"user_id\"]))))\n",
    "unique_city = np.unique(np.concatenate(list(interactions.batch(1_000).map(lambda x: x[\"customer_city\"]))))\n",
    "unique_product_category = np.unique(np.concatenate(list(interactions.batch(1_000).map(lambda x: x[\"product_category\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc5ebdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dimension = 32\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        ## user id\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "                                                    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                                    vocabulary=unique_user_ids, mask_token=None),\n",
    "                                                    tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "                                                    ])\n",
    "        #timestamp\n",
    "        self.timestamp_embedding = tf.keras.Sequential([\n",
    "                                    tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),\n",
    "                                    tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "                                ])\n",
    "        self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "\n",
    "        self.normalized_timestamp.adapt(timestamps)\n",
    "        \n",
    "        # city features\n",
    "        self.city_embedding = tf.keras.Sequential([\n",
    "                                          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                            vocabulary=unique_city, mask_token=None),\n",
    "                                          tf.keras.layers.Embedding(len(unique_city) + 1, self.embedding_dimension)\n",
    "                                        ])\n",
    "        self.city_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "                                                                                        max_tokens=max_tokens)\n",
    "        self.city_text_embedding = tf.keras.Sequential([\n",
    "                                  self.city_vectorizer,\n",
    "                                  tf.keras.layers.Embedding(max_tokens, self.embedding_dimension, mask_zero=True),\n",
    "                                  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "                                ])\n",
    "\n",
    "        self.city_vectorizer.adapt(city)    \n",
    "              \n",
    "        # product category  \n",
    "        self.category_embedding = tf.keras.Sequential([\n",
    "                                  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                    vocabulary=unique_product_category, mask_token=None),\n",
    "                                  tf.keras.layers.Embedding(len(unique_product_category) + 1, self.embedding_dimension)\n",
    "                                ])\n",
    "        \n",
    "        self.category_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "                                                                                        max_tokens=max_tokens)\n",
    "        self.category_text_embedding = tf.keras.Sequential([\n",
    "                                  self.category_vectorizer,\n",
    "                                  tf.keras.layers.Embedding(max_tokens, self.embedding_dimension, mask_zero=True),\n",
    "                                  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "                                ])\n",
    "\n",
    "        self.category_vectorizer.adapt(category)\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Take the input dictionary, pass it through each input layer,\n",
    "        # and concatenate the result.\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "            self.normalized_timestamp(inputs[\"timestamp\"]),\n",
    "            self.city_embedding(inputs[\"customer_city\"]),\n",
    "            self.city_text_embedding(inputs[\"customer_city\"]),\n",
    "            self.category_embedding(inputs[\"product_category\"]),\n",
    "            self.category_text_embedding(inputs[\"product_category\"]),\n",
    "#             self.category_embedding(['product_category'])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "680d9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes, projection_dim=None):\n",
    "        \"\"\"Model for encoding user queries.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # We first use the user model for generating embeddings.\n",
    "        self.embedding_model = UserModel()\n",
    "            \n",
    "#         self.dense_layers = tf.keras.Sequential([\n",
    "#                                     tfrs.layers.dcn.Cross(projection_dim=projection_dim,\n",
    "#                                                           kernel_initializer=\"glorot_uniform\"),\n",
    "#                                     tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#                                     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#                                     tf.keras.layers.Dense(1)\n",
    "#             ])\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(tfrs.layers.dcn.Cross(projection_dim=projection_dim,\n",
    "                                        kernel_initializer=\"glorot_uniform\"))\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cec2e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dimension = 32\n",
    "\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=unique_item_titles,mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_item_titles) + 1, self.embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "          self.title_vectorizer,\n",
    "          tf.keras.layers.Embedding(max_tokens, self.embedding_dimension, mask_zero=True),\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer.adapt(items)\n",
    "\n",
    "    def call(self, titles):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(titles),\n",
    "            self.title_text_embedding(titles),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d0918d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding movies.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes, projection_dim=None):\n",
    "        \"\"\"Model for encoding movies.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_model = ItemModel()\n",
    "\n",
    "         # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(tfrs.layers.dcn.Cross(projection_dim=projection_dim,\n",
    "                                                kernel_initializer=\"glorot_uniform\"))\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fb0a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossDNNModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, layer_sizes, rating_weight: float, retrieval_weight: float, projection_dim=None ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.query_model : tf.keras.Model = QueryModel(layer_sizes)\n",
    "        self.candidate_model : tf.keras.Model = CandidateModel(layer_sizes)\n",
    "        \n",
    "        ## rating and retrieval task.\n",
    "        \n",
    "        self.rating_task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "                 \n",
    "        self.retrieval_task : tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=items.batch(128).map(self.candidate_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        \n",
    "        # We only pass the user id and timestamp features into the query model. This\n",
    "        # is to ensure that the training inputs would have the same keys as the\n",
    "        # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "        # error when loading the query model after saving it.\n",
    "        #ratings = features.pop(\"quantity\")\n",
    "        \n",
    "        query_embeddings = self.query_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"timestamp\": features[\"timestamp\"],\n",
    "            \"customer_city\": features[\"customer_city\"],\n",
    "            \"product_category\": features[\"product_category\"],\n",
    "        })\n",
    "    \n",
    "        item_embeddings = self.candidate_model(features[\"product_id\"])       \n",
    "        retrieval_loss = self.retrieval_task(query_embeddings, item_embeddings)\n",
    "    \n",
    "    \n",
    "        return self.retrieval_task(query_embeddings, item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01d4ac81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:121 adapt_step  *\n        self._adapt_maybe_build(data)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:284 _adapt_maybe_build  **\n        self.build(data_shape)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\normalization.py:145 build\n        raise ValueError(\n\n    ValueError: All `axis` values to be kept must have known shape. Got axis: (-1,), input shape: [None], with unknown axis at index: 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-106b0a110c68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcached_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model = CrossDNNModel([32], rating_weight=0.5, retrieval_weight=0.5, \n\u001b[0m\u001b[0;32m      5\u001b[0m                       projection_dim=None)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-616542b185cf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layer_sizes, rating_weight, retrieval_weight, projection_dim)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_model\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQueryModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcandidate_model\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCandidateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-5ec47107141f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layer_sizes, projection_dim)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# We first use the user model for generating embeddings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUserModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         self.dense_layers = tf.keras.Sequential([\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-3c17dd91fd6e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized_timestamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# city features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[0;32m    246\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:121 adapt_step  *\n        self._adapt_maybe_build(data)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:284 _adapt_maybe_build  **\n        self.build(data_shape)\n    C:\\Users\\joaoa\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\normalization.py:145 build\n        raise ValueError(\n\n    ValueError: All `axis` values to be kept must have known shape. Got axis: (-1,), input shape: [None], with unknown axis at index: 0\n"
     ]
    }
   ],
   "source": [
    "cached_train = train.shuffle(len(masterdf)).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model = CrossDNNModel([32], rating_weight=0.5, retrieval_weight=0.5, \n",
    "                      projection_dim=None)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, validation_data=cached_test,\n",
    "        validation_freq=5, epochs=3)\n",
    "\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Retrieval top-50 accuracy: {metrics['factorized_top_k/top_50_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Retrieval top-10 accuracy: {metrics['factorized_top_k/top_10_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Retrieval top-5 accuracy: {metrics['factorized_top_k/top_5_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Retrieval top-1 accuracy: {metrics['factorized_top_k/top_1_categorical_accuracy']:.3f}.\")\n",
    "# print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36b8723a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'query_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-047f72f8f239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorized_top_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBruteForce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcandidate_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midentifiers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minteractions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best recommendations: {nn(row)[1].numpy()[:, :3].tolist()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'query_model'"
     ]
    }
   ],
   "source": [
    "nn = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
    "nn.index(items.batch(1024).map(model.candidate_model), identifiers=items)\n",
    "for row in interactions.batch(1).take(1):\n",
    "    print(f\"Best recommendations: {nn(row)[1].numpy()[:, :3].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "## access the kernel inside cross-network in the first later of the sequential layer in querymodel\n",
    "mat = model.query_model.dense_layers.get_layer(index=0)._dense.kernel\n",
    "features =  ['user_id', \n",
    "            'customer_city',\n",
    "            'product_id', \n",
    "            'product_category',\n",
    "            'quantity', \n",
    "            'timestamp']\n",
    "\n",
    "block_norm = np.ones([len(features), len(features)])\n",
    "\n",
    "dim = model.query_model.embedding_model.embedding_dimension\n",
    "\n",
    "# Compute the norms of the blocks.\n",
    "for i in range(len(features)):\n",
    "    for j in range(len(features)):\n",
    "        block = mat[i * dim:(i + 1) * dim,\n",
    "                    j * dim:(j + 1) * dim]\n",
    "        block_norm[i,j] = np.linalg.norm(block, ord=\"fro\")\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "im = plt.matshow(block_norm, cmap=plt.cm.Blues)\n",
    "ax = plt.gca()\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "cax.tick_params(labelsize=10) \n",
    "_ = ax.set_xticklabels([\"\"] + features, rotation=45, ha=\"left\", fontsize=10)\n",
    "_ = ax.set_yticklabels([\"\"] + features, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364e26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
